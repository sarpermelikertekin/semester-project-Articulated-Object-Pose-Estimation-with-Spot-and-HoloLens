{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Spot, 162.0ms\n",
      "Speed: 5.4ms preprocess, 162.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "<class 'ultralytics.engine.results.Results'>\n",
      "<class 'torch.Tensor'>\n",
      "box\n",
      "51 13 244 156\n",
      "[[[199.2679443359375, 44.581871032714844], [215.95956420898438, 38.14536666870117], [176.75657653808594, 79.40859985351562], [210.40431213378906, 143.5410614013672], [174.3384552001953, 49.679744720458984], [136.67909240722656, 92.21648406982422], [174.7793426513672, 151.26258850097656], [0.0, 0.0], [103.9952163696289, 64.31573486328125], [130.781494140625, 116.8177719116211], [85.92278289794922, 31.689178466796875], [57.89698028564453, 65.7940444946289], [93.70525360107422, 128.13059997558594]]]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model_path = 'C:\\\\Users\\\\sakar\\\\Semester Project\\\\semester-project-yolov8\\\\runs\\\\pose\\\\train22\\weights\\\\last.pt'\n",
    "image_path = 'C:\\\\Users\\\\sakar\\\\Semester Project\\\\semester-project-yolov8\\\\spot.jpg'\n",
    "#image_path = 'C:\\\\Users\\\\sakar\\\\Semester Project\\\\Spot Datasets\\\\11 - Spot and AnyMAL\\\\test\\\\images\\\\1006.png'\n",
    "\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Resize the image to 1086 x 611\n",
    "resized_img = cv2.resize(img, (1086, 611))\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Run inference on the resized image\n",
    "results = model(img)[0]\n",
    "print(type(results))\n",
    "\n",
    "for result in results:\n",
    "    # Get the bounding box in xyxy format\n",
    "    box = result.boxes.xyxy[0]\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    \n",
    "    print(type(box))\n",
    "    print('box')\n",
    "    print(x1, y1, x2, y2)\n",
    "\n",
    "\n",
    "    # Draw the bounding box on the resized image\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Draw keypoints on the resized image\n",
    "    keypoints = result.keypoints.xy.tolist()\n",
    "    print(keypoints)\n",
    "    print(type(keypoints))\n",
    "\n",
    "    for keypoint_indx, (x, y) in enumerate(keypoints[0]):\n",
    "        if x != 0 and y != 0:\n",
    "            cv2.putText(img, str(keypoint_indx), (int(x), int(y)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display the resized image\n",
    "cv2.imshow('Resized Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: lapx 0.5.5\n",
      "Uninstalling lapx-0.5.5:\n",
      "  Successfully uninstalled lapx-0.5.5\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall lapx -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lapx>=0.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "newenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
